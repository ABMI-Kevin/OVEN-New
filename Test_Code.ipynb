{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does this open?!?!?!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/OVEN-test/')\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder of recordings for analysis, uncomment the appropriate line to define the directory holding your recording files\n",
    "\n",
    "# If running on a local machine then modify and use the following\n",
    "#RECORDINGS = 'C:/file/path/here/'\n",
    "\n",
    "# If running on Google Colan then modify and use the following\n",
    "RECORDINGS = '/content/drive/MyDrive/OVEN-test/Recordings_OVEN-test/'\n",
    "#RECORDINGS = '/content/drive/MyDrive/file/recording/path/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(RECORDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code!!!!!!!\n",
    "\n",
    "def highpass_filter(y, fc, sr):\n",
    "    nyq = 0.5 * sr\n",
    "    b, a = butter(4, fc/nyq, 'high')\n",
    "    return filtfilt(b, a, y)\n",
    "\n",
    "def normalise_audio(y, sr=16000):\n",
    "    y = highpass_filter(y=y, fc=500.0, sr=sr)\n",
    "    y -= np.mean(y)\n",
    "    return y\n",
    "\n",
    "def spectrogram_from_audio(y, sr):\n",
    "    sr = 16000\n",
    "    n_fft = 128\n",
    "    hop_length = 64\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window=np.blackman)[10:,:] # remove DC\n",
    "    D = librosa.power_to_db(np.abs(D)**2, ref=1.0)\n",
    "    D = np.swapaxes(D,0,1)[np.newaxis,np.newaxis,:,:] # [batch,height,width,channels]\n",
    "    return D\n",
    "\n",
    "def process_directory(recordings):\n",
    "    # make sure there is somewhere to save results\n",
    "    results_location = os.path.join(recordings, 'results')\n",
    "    if not os.path.exists(results_location):\n",
    "        os.makedirs(results_location)\n",
    "\n",
    "    # find tensorflow model files\n",
    "    meta_graph_path = 'oven-model-22022017.meta'\n",
    "    checkpoint_path = 'oven-model-22022017'\n",
    "\n",
    "    # list all audio files in directory\n",
    "    audio_files = librosa.util.find_files(recordings, ext=['flac', 'wav'], recurse=True, case_sensitive=False, limit=None, offset=0)\n",
    "    audio_files = list(set(audio_files)) # remove duplicates - not sure why find_files produces them!\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        new_saver = tf.compat.v1.train.import_meta_graph(meta_graph_path)\n",
    "        new_saver.restore(sess, checkpoint_path)\n",
    "        features = tf.compat.v1.get_collection('input')[0]\n",
    "        is_training = tf.compat.v1.get_collection('is_training')[0]\n",
    "        level = tf.compat.v1.get_collection('level')[0]\n",
    "        detection_fn = tf.compat.v1.get_collection('detection_fn')[0]\n",
    "\n",
    "        for filename in tqdm_notebook(audio_files):\n",
    "            y, sr = librosa.load(filename, sr=16000, mono=True)\n",
    "            y = normalise_audio(y)\n",
    "            S = spectrogram_from_audio(y, sr)\n",
    "            level_dB, detection_function = sess.run([level, detection_fn], feed_dict={features: S, is_training: False})\n",
    "            level_dB = level_dB[0,0,:,0]\n",
    "            detection_function = detection_function[0,0,:,0]\n",
    "            detection_function = expit(detection_function)\n",
    "            duration_secs = y.size / float(sr)\n",
    "            times = np.interp(np.arange(detection_function.size), [0,detection_function.size-1], [0,duration_secs])\n",
    "            df = pd.DataFrame({'0': times, '1': detection_function, '2': level_dB})\n",
    "\n",
    "            base = os.path.basename(filename)\n",
    "            filename = os.path.splitext(base)[0]\n",
    "            savename = os.path.join(results_location, filename + '_detection_function.csv')\n",
    "            df.to_csv(savename, header=False, index=False)\n",
    "\n",
    "process_directory(RECORDINGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
